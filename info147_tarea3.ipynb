{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3: Los K-vecinos \n",
    "\n",
    "## Introducción\n",
    "\n",
    "<img src=\"images/vecinos.png\" width=\"400\">\n",
    "\n",
    "Los $K$-vecinos es un método clásico y muy sencillo para hacer clasificación de datos, que se basa en predecir la etiqueta de un dato basado en las etiquetas de los datos de entrenamiento que más se le parecen. La siguiente figura describe graficamente los tres pasos del algoritmo\n",
    "\n",
    "<img src=\"images/algoritmo.png\" width=\"600\">\n",
    "\n",
    "En este caso es clave definir una noción de distancia entre los ejemplos y también especificar un valor adecuado para $K$, la cantidad de vecinos que influyen en la predicción.\n",
    "\n",
    "## Formalismo matemático\n",
    "\n",
    "Sea una base de datos $E = \\{(x_j, y_j), j=1, \\ldots, N\\}$, con $N$ ejemplos donde $x_j \\in \\mathbb{R}^{D}$ es un atributo d-dimensional e $y_j \\in \\{0, 1, 2, \\ldots, C-1\\}$ son sus etiquetas de clase. Sea ahora una segunda base de datos $T = \\{(z_i), i=1, \\ldots, M\\}$ con $M$ ejemplos donde $z_i \\in \\mathbb{R}^{D}$ es un atributo d-dimensional. Esta base de datos no tiene etiquetas. El objetivo es clasificar los ejemplos de $T$ en base a las etiquetas de los $K$ ejemplos más cercanos de la base de datos $E$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo para clasificar el i-esimo elemento de Z es\n",
    "\n",
    "**Paso 1** Calculamos la distancia entre $z_i$ y cada elemento de $E$ usando\n",
    "\n",
    "$$\n",
    "d(z_i, x_j) = \\left ( \\sum_{d=1}^D  |z_{id} - x_{jd}|^p \\right)^{1/p}\n",
    "$$\n",
    "\n",
    "que se conoce como [distancia de Minkowski](https://en.wikipedia.org/wiki/Minkowski_distance). Para el caso $p=2$ se recupera la clásica distancia euclidiana.\n",
    "\n",
    "**Paso 2** Buscamos las $k$ tuplas $(x_k^{(i)}, y_k^{(i)})$ con menor distancia a $z_i$\n",
    "\n",
    "**Paso 3** Seleccionamos la clase de $z_i$ según\n",
    "\n",
    "$$\n",
    "\\text{arg}\\max_{c=0, 1, \\ldots} \\sum_{k=1}^K \\frac{\\mathbb{1}(c=y^{(i)}_k)}{d(z_i, x^{(i)}_k)}\n",
    "$$\n",
    "\n",
    "donde \n",
    "\n",
    "$$\n",
    "\\mathbb{1}(a=b) = \\begin{cases} 1 & \\text{si } a=b \\\\ 0 &  \\text{si } a\\neq b \\end{cases}\n",
    "$$\n",
    "\n",
    "se conoce como función indicadora. Esta versión particular del algoritmo se conoce como clasificador de $k$ vecinos ponderado, ya que una menor distancia (mayor cercanía) aumenta el peso del voto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones generales \n",
    "\n",
    "1. Forme un grupo de **máximo tres estudiantes**\n",
    "1. Versione su trabajo usando un **repositorio privado de github**. Agregue a sus compañeros y a su profesor (usuario github: phuijse) en la pestaña *Settings/Manage access*. No se aceptarán consultas de programación si no se cumple este requisito\n",
    "1. Su tarea se evaluará en base al último commit antes de la fecha de entrega: **23:59 del Martes 20 de Julio de 2021**. La nota se calcula como (\"pt totales\" + 1)\n",
    "1. [Sean leales y honestos](https://www.acm.org/about-acm/code-of-ethics-in-spanish), no copie ni comparta resultados con otros grupos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones de la actividad\n",
    "\n",
    "- (1pt) Considere la implementación \"ingenua\" del algoritmo KNN que se adjunta a esta tarea con los parámetros $p$ y $k$ por defecto\n",
    "    - Use la función adjunta `create_data` para crear un conjunto de `N=1000` datos\n",
    "    - Realice un profiling completo de la función `KNN` usando las magias `timeit`, `prun` y `lprun`\n",
    "    - Reporte sus resultados y comente sobre los cuellos de botella del algoritmo\n",
    "- (2pt) Implemente una nueva versión de la función `KNN`\n",
    "    - Utilice `Cython` con tipos fijos, vistas de arreglos y funciones de la librería estándar matemática de `C`\n",
    "    - Muestre que obtiene el mismo resultado que la versión original\n",
    "    - Grafique el *speed-up* de su nueva función con respecto a la implementación \"inocente\" original para $N=[10, 50, 100, 500, 1000, 5000, 10000]$\n",
    "- (2pt) Usando la nueva versión de `KNN` y el conjunto de `N=1000` datos creados con `create_data` realice una validación cruzada en el conjunto $E$ para encontrar el mejor valor de los parámetros $k$ y $p$\n",
    "- (1pt) Evalue su mejor clasificador en el conjunto $T$ y haga un reporte completo de resultados que incluya curvas ROC y las métricas vistas en el curso. Muestre una gráfica de la frontera de decisión de su clasificador en el rango $[(-2,2), (-2,2)]$\n",
    "\n",
    "**Justifique adecuadamente todas sus decisiones de diseño**\n",
    "\n",
    "A continuación se muestra una gráfica con los datos a utilizar en esta tarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T02:56:05.546081Z",
     "start_time": "2020-08-22T02:56:05.439738Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from funciones import create_data, KNN\n",
    "\n",
    "E, T = create_data(N=1000)\n",
    "x, y = E # Use E para realizar validación cruzada\n",
    "z, w = T # Use las etiquetas w para evaluar sus resultados finales\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "for c in np.unique(y):\n",
    "    mask = y == c\n",
    "    ax.scatter(x[mask, 0], x[mask, 1], label=f\"E: {c}\", s=10)\n",
    "ax.scatter(z[:, 0], z[:, 1], c='k', s=10, marker='x',  alpha=0.2, label='T')\n",
    "ax.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mediciones de KNN\n",
    "\n",
    "#### 1.1 Utilizando la magia %timeit\n",
    "\n",
    "Podemos medir el tiempo promedio de un script, función o expresión de Python de forma conveniente usando la magia timeit. Esta magia se basa en el módulo estándar de Python timeit.\n",
    "En este caso, se ejecuta 4 veces la función, realizando 2 loops en cada iteración y especificamos que el resultado tenga una precisión de 8 dígitos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeitResult = %timeit -r4 -n2 -p8 -o Z_Y_1 = KNN(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Utilizando la magia %prun \n",
    "\n",
    "Se debe instalar SnakeViz\n",
    "\n",
    "    conda install snakeviz\n",
    "\n",
    "Esto retorna una tabla con las siguientes filas\n",
    "- ncalls: Número de veces que se llama la función\n",
    "- tottime: Tiempo total en dicha función (sin contar subfunciones)\n",
    "- percall: ttime/ncalls\n",
    "- cumtime: Tiempo total en dicha función y sus subfunciones (tiempo de función recursiva)\n",
    "- percall: cumtime/ncalls\n",
    "\n",
    "(En general, el tiempo total es mayor que el que medimos con time y timeit. Esto se debe al overhead de prun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%prun -s cumtime Z_Y_1 = KNN(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext snakeviz\n",
    "%snakeviz KNN(x,y,z) #-t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Utilizando la magia %lprun\n",
    "\n",
    "Debes instalar la extensión externa \"line_profiler\"\n",
    "\n",
    "    conda install line_profiler\n",
    "\n",
    "\n",
    "Esta magia nos permite estudiar el tiempo de ejecución de cada linea de nuestro código por separado.\n",
    "\n",
    "Ejecutarla nos levantará una pestaña con una tabla que tiene una fila por linea de código y las siguientes columnas\n",
    "\n",
    "- Line: Número de la linea dentro del código fuente\n",
    "\n",
    "- Hits: La cantidad de veces que se llama a esa linea\n",
    "\n",
    "- Time: Tiempo total de dicha linea\n",
    "\n",
    "- Per hit: Tiempo total dividido la cantidad de llamadas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f KNN KNN(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las mediciones realizadas podemos concluir lo siguiente:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando la magia **%prun** pudimos evidenciar que gran porcentaje del tiempo de ejecución se invierte en funciones built-in de python y que se utilizan en KNN. Una de estas funciones pertenece a Numpy, especificamente el método reduce que modifica la dimensionalidad del arreglo. \n",
    "\n",
    "Utilizando la magia **%lprun** vemos que un 94.6% del tiempo de cómputo se efectúa al ejecutar la línea 21 de la función KNN. Esta función consiste en realizar operaciones matemáticas que calculan la distancia entre vecinos. Cabe destacar que esta funcion se encuentra dentro de dos for anidados y es ejecutada MxN veces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. KNN en Cython\n",
    "\n",
    "Debes instalar cython\n",
    "\n",
    "    conda install cython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con esto tendremos disponible la magia de bloque %%cython\n",
    "\n",
    "Un bloque donde se use esta magia acepta lenguaje cython y se compila al ejecutarlo. Luego podremos llamar las funciones de ese bloque desde bloques regulares de Python\n",
    "\n",
    "Si surgen errores de compulación estos aparecen como la salida del bloque. Notar que este bloque está “desconectado” del resto del notebook, por lo que debe tener sus propios import\n",
    "\n",
    "La magia tiene las siguientes opciones\n",
    "\n",
    "    -a, (annotate) retorna un profile linea a linea indicando con amarillo las llamadas a CPython (mientras más llamadas más lento es nuestro código)\n",
    "    -+, Usar C++ en lugar de C\n",
    "    -c, Argumentos de compilación\n",
    "    -l, librerías para linkear a nuestro código\n",
    "    -L, directorio con librerías\n",
    "    -I, directorio con cabeceras (include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requerido para Mac OS X\n",
    "\n",
    "#import os\n",
    "#os.environ[\"CC\"] = \"/usr/local/opt/llvm/bin/clang\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%cython -l m --compile-args=-fopenmp --link-args=-fopenmp --force\n",
    "\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as npc\n",
    "from cython.parallel import prange\n",
    "\n",
    "cdef extern from \"math.h\" nogil:\n",
    "    double fabs(double)\n",
    "    double pow(double,double)\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.initializedcheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "\n",
    "cpdef npc.ndarray CKNN(double [:,::1] X, long [:] Y, double [:,::1] Z, unsigned char k=5, double p = 2.0):\n",
    "    \n",
    "    # Clases\n",
    "    cdef long [:] c = np.unique(Y) \n",
    "    \n",
    "    cdef unsigned short C = c.shape[0] # Número de clases\n",
    "    cdef unsigned short N = X.shape[0] # Número de muestras conocidas\n",
    "    cdef unsigned short D = X.shape[1] # Número de dimensiones\n",
    "    cdef unsigned short M = Z.shape[0] # Número de muestras a entrenar\n",
    "        \n",
    "    # Exponente inv\n",
    "    cdef double expo = 1.0/p;\n",
    "    \n",
    "    # Indices de los k mas cercanos\n",
    "    cdef unsigned short [:,::1] kInds = np.zeros((M,k),dtype='uint16')\n",
    "    \n",
    "    # Distancias de los k mas cercanos\n",
    "    cdef double [:,::1] kDists = np.full((M,k),1.7976931348623157e+308,dtype='float64')\n",
    "    \n",
    "    # Indice de la distancia más grande ( dentro de las k más pequeñas )\n",
    "    cdef unsigned short [:] maxDistIndex = np.zeros(M,dtype='uint16')\n",
    "    \n",
    "    # Indice de la clase ganadora\n",
    "    cdef unsigned short [:] winnerClassIndex = np.zeros(M,dtype='uint16')\n",
    "    cdef double [:] winnerClassDist = np.zeros(M,dtype='float64')\n",
    "    \n",
    "    # Variable para almacenar suma de distancias inversas por clase ( para decidir clase )\n",
    "    cdef double [:,::1] cRes = np.zeros((M,C),dtype='float64')\n",
    "    \n",
    "    # Variable temporal para calcular distancia\n",
    "    cdef double [:] dist = np.zeros(M,dtype='float64')\n",
    "    \n",
    "    # Resultados\n",
    "    cdef unsigned char [:] YZ = np.zeros(M,dtype='uint8')\n",
    "    \n",
    "    # Indices\n",
    "    cdef short i,j,d,l = 0\n",
    "    \n",
    "    # Loop cada elemento de Z\n",
    "    with nogil:\n",
    "        for i in prange(M,num_threads=12):\n",
    "\n",
    "            # Loop cada elemento de X\n",
    "            for j in range(N):\n",
    "\n",
    "                # Calcula distancia\n",
    "                dist[i] = 0.0\n",
    "                for d in range(D):\n",
    "                    dist[i] += pow(fabs(Z[i,d] - X[j,d]),p)\n",
    "                dist[i] = pow(dist[i],expo)\n",
    "\n",
    "                # Si la distancia es menor que la mayor en kDists\n",
    "                if dist[i] < kDists[i,maxDistIndex[i]]:\n",
    "\n",
    "                    # Reemplaza el valor\n",
    "                    kDists[i,maxDistIndex[i]] = dist[i]\n",
    "\n",
    "                    # Guarda el índice del elemento X actual\n",
    "                    kInds[i,maxDistIndex[i]] = j\n",
    "\n",
    "                    # Vuelve a buscar el mayor actual en kDists\n",
    "                    dist[i] = 0\n",
    "                    for l in range(k):\n",
    "                        if kDists[i,l] > dist[i]:\n",
    "                            dist[i] = kDists[i,l]\n",
    "                            maxDistIndex[i] = l\n",
    "\n",
    "            # Calcula la cercanía ponderada por distancia de cada clase\n",
    "            for d in range(k):\n",
    "\n",
    "                # Suponiendo que los nombres de las clases siempre son 0,1,...,C-1\n",
    "                cRes[i,Y[kInds[i,d]]] += 1.0/kDists[i,d]\n",
    "\n",
    "            # Busca la clase ganadora\n",
    "            for d in range(C):\n",
    "                if cRes[i,d] > winnerClassDist[i]:\n",
    "                    winnerClassDist[i] = cRes[i,d]\n",
    "                    winnerClassIndex[i] = d\n",
    "\n",
    "            # Guarda la clase ganadora en el arreglo\n",
    "            YZ[i] = c[winnerClassIndex[i]]\n",
    "                        \n",
    "            \n",
    "    return YZ.base\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r10 -n10 CKNN(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r2 -n2 KNN(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def SKLEARN(x,y,z):\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5,weights='distance',p=2,)\n",
    "    knn.fit(x,y)\n",
    "    knn.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SOLO PARA PROBAR METRICAS\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5,weights='distance',p=2,)\n",
    "knn.fit(x,y)\n",
    "knn.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit -r10 -n10 SKLEARN(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CKNN(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KNN(x,y,z).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Gráfica del Speed-up\n",
    "El speed-up es el tiempo de la nueva rutina dividido el tiempo de referencia (rutina secuencial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4), tight_layout=True)\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=2)\n",
    "for train_index, val_index in kf.split(x):\n",
    "    knn.fit(x[train_index], y[train_index])\n",
    "    knn.score(x[val_index], y[val_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Métricas que evalúan el clasificador\n",
    "Se implementaron distintas métricas que permiten evaluar la exactitud y desempeño de los algoritmos KNN al momento de identificar las dos mitades de círculos entrelazados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Matriz de Confusión\n",
    "La matriz de confusión es una herramienta muy útil para valorar cómo de bueno es un modelo clasificación basado en aprendizaje automático. En particular, sirve para mostrar de forma explícita cuándo una clase es confundida con otra, lo cual nos, permite trabajar de forma separada con distintos tipos de error. \n",
    "\n",
    "En una matriz de confusión, por lo general:\n",
    "\n",
    "- los elementos de la diagonal representan las clasificaciones correctas\n",
    "\n",
    "- los elementos fuera de la diagonal representan las clasificaciones erroneas\n",
    "\n",
    "- las filas corresponden a las clases reales\n",
    "\n",
    "- las columnas corresponden a las clases predichas por el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4), tight_layout=True)\n",
    "\n",
    "plot_confusion_matrix(knn, # Clasificador\n",
    "                      x, # Datos\n",
    "                      y, # Etiquetas\n",
    "                      ax=ax, # subeje para gráficar\n",
    "                      display_labels=np.array(['Naranjo', 'Azul']), #Nombres de las clases\n",
    "                      cmap=plt.cm.plasma, # Escala de colores\n",
    "                      normalize=None #Permite escoger entre cantidades y porcentajes\n",
    "                     );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Exactitud\n",
    "El accuracy se calcula como la cantidad de ejemplos predichos correctamente dividido por la cantidad total de ejemplos y es un valor en el rango [0,1]. Por definición corresponde a la suma de la diagonal de la matriz de confusión dividido por el total de ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat = knn.predict(x)\n",
    "\n",
    "print(accuracy_score(y, yhat))\n",
    "\n",
    "print(knn.score(x[:, :2], y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Curva de desempeño\n",
    "\n",
    "En problemas de clasificación binaria es mucho más informativo medir el desempeño utilizando curvas Receiver operating characteristic (ROC), que son curvas en las que se presenta la sensibilidad (o verdaderos positivos) en función de los falsos positivos (complementario de la especificidad) para distintos puntos de corte.\n",
    "\n",
    "A modo de resumen, una interpretación superficial de las curvas sigue la siguiente figura.\n",
    "\n",
    "<img src=\"images/roc.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y, knn.predict_proba(x)[:, 1])\n",
    "idx = np.where(tpr > 0.9)[0][0]\n",
    "print(f\"{fpr[idx]:0.4f}, {tpr[idx]:0.4f}, {thresholds[idx]:0.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(fpr, tpr)\n",
    "ax.scatter(fpr[idx], tpr[idx], s=50, c='k')\n",
    "ax.set_xlabel('Tasa de falsos positivos')\n",
    "ax.set_ylabel('Tasa de verdaderos positivos');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
