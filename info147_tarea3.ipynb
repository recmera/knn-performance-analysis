{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3: Los K-vecinos \n",
    "\n",
    "## Introducción\n",
    "\n",
    "<img src=\"images/vecinos.png\" width=\"400\">\n",
    "\n",
    "Los $K$-vecinos es un método clásico y muy sencillo para hacer clasificación de datos, que se basa en predecir la etiqueta de un dato basado en las etiquetas de los datos de entrenamiento que más se le parecen. La siguiente figura describe graficamente los tres pasos del algoritmo\n",
    "\n",
    "<img src=\"images/algoritmo.png\" width=\"600\">\n",
    "\n",
    "En este caso es clave definir una noción de distancia entre los ejemplos y también especificar un valor adecuado para $K$, la cantidad de vecinos que influyen en la predicción.\n",
    "\n",
    "## Formalismo matemático\n",
    "\n",
    "Sea una base de datos $E = \\{(x_j, y_j), j=1, \\ldots, N\\}$, con $N$ ejemplos donde $x_j \\in \\mathbb{R}^{D}$ es un atributo d-dimensional e $y_j \\in \\{0, 1, 2, \\ldots, C-1\\}$ son sus etiquetas de clase. Sea ahora una segunda base de datos $T = \\{(z_i), i=1, \\ldots, M\\}$ con $M$ ejemplos donde $z_i \\in \\mathbb{R}^{D}$ es un atributo d-dimensional. Esta base de datos no tiene etiquetas. El objetivo es clasificar los ejemplos de $T$ en base a las etiquetas de los $K$ ejemplos más cercanos de la base de datos $E$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo para clasificar el i-esimo elemento de Z es\n",
    "\n",
    "**Paso 1** Calculamos la distancia entre $z_i$ y cada elemento de $E$ usando\n",
    "\n",
    "$$\n",
    "d(z_i, x_j) = \\left ( \\sum_{d=1}^D  |z_{id} - x_{jd}|^p \\right)^{1/p}\n",
    "$$\n",
    "\n",
    "que se conoce como [distancia de Minkowski](https://en.wikipedia.org/wiki/Minkowski_distance). Para el caso $p=2$ se recupera la clásica distancia euclidiana.\n",
    "\n",
    "**Paso 2** Buscamos las $k$ tuplas $(x_k^{(i)}, y_k^{(i)})$ con menor distancia a $z_i$\n",
    "\n",
    "**Paso 3** Seleccionamos la clase de $z_i$ según\n",
    "\n",
    "$$\n",
    "\\text{arg}\\max_{c=0, 1, \\ldots} \\sum_{k=1}^K \\frac{\\mathbb{1}(c=y^{(i)}_k)}{d(z_i, x^{(i)}_k)}\n",
    "$$\n",
    "\n",
    "donde \n",
    "\n",
    "$$\n",
    "\\mathbb{1}(a=b) = \\begin{cases} 1 & \\text{si } a=b \\\\ 0 &  \\text{si } a\\neq b \\end{cases}\n",
    "$$\n",
    "\n",
    "se conoce como función indicadora. Esta versión particular del algoritmo se conoce como clasificador de $k$ vecinos ponderado, ya que una menor distancia (mayor cercanía) aumenta el peso del voto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones generales \n",
    "\n",
    "1. Forme un grupo de **máximo tres estudiantes**\n",
    "1. Versione su trabajo usando un **repositorio privado de github**. Agregue a sus compañeros y a su profesor (usuario github: phuijse) en la pestaña *Settings/Manage access*. No se aceptarán consultas de programación si no se cumple este requisito\n",
    "1. Su tarea se evaluará en base al último commit antes de la fecha de entrega: **23:59 del Martes 20 de Julio de 2021**. La nota se calcula como (\"pt totales\" + 1)\n",
    "1. [Sean leales y honestos](https://www.acm.org/about-acm/code-of-ethics-in-spanish), no copie ni comparta resultados con otros grupos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones de la actividad\n",
    "\n",
    "- (1pt) Considere la implementación \"ingenua\" del algoritmo KNN que se adjunta a esta tarea con los parámetros $p$ y $k$ por defecto\n",
    "    - Use la función adjunta `create_data` para crear un conjunto de `N=1000` datos\n",
    "    - Realice un profiling completo de la función `KNN` usando las magias `timeit`, `prun` y `lprun`\n",
    "    - Reporte sus resultados y comente sobre los cuellos de botella del algoritmo\n",
    "- (2pt) Implemente una nueva versión de la función `KNN`\n",
    "    - Utilice `Cython` con tipos fijos, vistas de arreglos y funciones de la librería estándar matemática de `C`\n",
    "    - Muestre que obtiene el mismo resultado que la versión original\n",
    "    - Grafique el *speed-up* de su nueva función con respecto a la implementación \"inocente\" original para $N=[10, 50, 100, 500, 1000, 5000, 10000]$\n",
    "- (2pt) Usando la nueva versión de `KNN` y el conjunto de `N=1000` datos creados con `create_data` realice una validación cruzada en el conjunto $E$ para encontrar el mejor valor de los parámetros $k$ y $p$\n",
    "- (1pt) Evalue su mejor clasificador en el conjunto $T$ y haga un reporte completo de resultados que incluya curvas ROC y las métricas vistas en el curso. Muestre una gráfica de la frontera de decisión de su clasificador en el rango $[(-2,2), (-2,2)]$\n",
    "\n",
    "**Justifique adecuadamente todas sus decisiones de diseño**\n",
    "\n",
    "A continuación se muestra una gráfica con los datos a utilizar en esta tarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T02:56:05.546081Z",
     "start_time": "2020-08-22T02:56:05.439738Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from funciones import create_data, KNN\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "E, T = create_data(N=1000)\n",
    "x, y = E # Use E para realizar validación cruzada\n",
    "z, w = T # Use las etiquetas w para evaluar sus resultados finales\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "for c in np.unique(y):\n",
    "    mask = y == c\n",
    "    ax.scatter(x[mask, 0], x[mask, 1], label=f\"E: {c}\", s=10)\n",
    "ax.scatter(z[:, 0], z[:, 1], c='k', s=10, marker='x',  alpha=0.2, label='T')\n",
    "ax.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mediciones de KNN\n",
    "\n",
    "### 1.1 Utilizando la magia %timeit\n",
    "\n",
    "Podemos medir el tiempo promedio de un script, función o expresión de Python de forma conveniente usando la magia timeit. Esta magia se basa en el módulo estándar de Python timeit.\n",
    "En este caso, se ejecuta 4 veces la función, realizando 2 loops en cada iteración y especificamos que el resultado tenga una precisión de 8 dígitos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeitResult = %timeit -r4 -n2 -p8 -o Z_Y_1 = KNN(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(timeitResult.all_runs)/float(len(timeitResult.all_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeitResult.compile_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que la función no parece ser muy eficiente ya que tarda aproximadamente 2 segundos en finalizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Utilizando la magia %prun \n",
    "\n",
    "Con **%prun** podemos visualizar el número de veces que son llamados los sub-métodos de una función, y el tiempo que consume cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%prun -s cumtime KNN(x,y,z)\n",
    "\n",
    "# Para facilitar la visualización también podemos usar SnakeViz.\n",
    "#%load_ext snakeviz\n",
    "#%snakeviz KNN(x,y,z) #-t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el tiempo total es mayor que el que medimos con timeit ( tarda aproximadamente 500 ms más ). Esto se debe al overhead introducido por prun.\n",
    "También pudimos evidenciar que gran parte del tiempo de ejecución se invierte en los método **reduce** y **sum**, los cuales no consumen mucho tiempo por llamado, pero si al invocarse 189000 veces. La operación más costosa es **argsort** pero por suerte solo se llama 1 vez. Si analizamos los tiempos acumulados, vemos que el cuello de botella se encuentra en los lugares donde se utiliza **sum**, por ejemplo en el cálculo de distancia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Utilizando la magia %lprun\n",
    "\n",
    "Esta magia nos permite estudiar el tiempo de ejecución y número de llamados de cada linea de nuestro código por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f KNN KNN(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que un 94.6% del tiempo de cómputo se efectúa al ejecutar la línea 21 de la función KNN. La operación de esa linea consiste en el cálculo de distancia entre vecinos. También podemos notar que los ciclos **for** ocupan un 4.1 % y que el método **argsort** aún siendo llamado 1 vez, consume el 0.3% del tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. KNN en Cython\n",
    "\n",
    "Implementamos 3 funciones de KNN con Cython **CKNN1**, **CKNN2** y **CKNN3**. En cada una vamos realizando mejoras respecto a la anterior. También incluimos la implementación KNN de sklearn para comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requerido para OpenMP en Mac OS X\n",
    "#import os\n",
    "#os.environ[\"CC\"] = \"/usr/local/opt/llvm/bin/clang\"\n",
    "\n",
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKNN1\n",
    "En la primera mejora definimos los tipos de cada variable ( donde sea posible ) y reemplazamos las funciones de numpy para calcular la distancia por un for y funciones de C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -l m\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as npc\n",
    "import cython\n",
    "\n",
    "cdef extern from \"math.h\":\n",
    "    double fabs(double)\n",
    "    double pow(double,double)\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cpdef npc.ndarray CKNN1(X, Y, Z, unsigned char k=5, double p = 2.0):\n",
    "\n",
    "    cdef long [:] C = np.unique(Y) \n",
    "    cdef unsigned short N = X.shape[0] # Número de muestras conocidas\n",
    "    cdef unsigned short D = X.shape[1] # Número de dimensiones\n",
    "    cdef unsigned short M = Z.shape[0] # Número de muestras a entrenar\n",
    "    \n",
    "    # Exponente inv\n",
    "    cdef double expo = 1.0/p;\n",
    "    \n",
    "    dist = np.zeros(shape=(M, N))\n",
    "    \n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            for d in range(D):\n",
    "                dist[i, j] += pow(fabs(Z[i,d] - X[j,d]),p)\n",
    "            dist[i, j] = pow(dist[i, j],expo)\n",
    "            \n",
    "    neighbours = np.argsort(dist, axis=1)[:, :k]\n",
    "    Z_Y = np.zeros(shape=(M, ))\n",
    "    for i in range(M):\n",
    "        criterion = np.zeros(shape=(len(C),))\n",
    "        for c in C:\n",
    "            criterion[c] = np.sum(1./dist[i, neighbours[i]][Y[neighbours[i]] == c])\n",
    "        Z_Y[i] = np.argmax(criterion)\n",
    "    return Z_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto logramos reducir el tiempo de 2000 ms a 470 ms (4 veces más rapido)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKNN2\n",
    "En la segunda mejora, reemplazamos las funciones de numpy para ordenar y calcular las clases. En vez de almacenar todas las distancias en un \"gran\" arreglo, utilizamos arreglos de largo K para ir almacenando las distancias más pequeñas de cada iteración junto los indices.\n",
    "De esas K distancias más pequeñas almacenamos la mayor para reemplazarla únicamente si la nueva distancia calculada es menor. De esta forma realizamos menos iteraciones para encontrar los K elementos que si ordenaramos los arreglos al final. Además al no utilizar numpy, no obtenemos errores al definir los tipos de datos del argumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%cython -l m\n",
    "\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as npc\n",
    "\n",
    "cdef extern from \"math.h\":\n",
    "    double fabs(double)\n",
    "    double pow(double,double)\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.initializedcheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cpdef npc.ndarray CKNN2(double [:,::1] X, long [:] Y, double [:,::1] Z, unsigned char k=5, double p = 2.0):\n",
    "    \n",
    "    # Clases\n",
    "    cdef long [:] c = np.unique(Y) \n",
    "    \n",
    "    cdef unsigned short C = c.shape[0] # Número de clases\n",
    "    cdef unsigned short N = X.shape[0] # Número de muestras conocidas\n",
    "    cdef unsigned short D = X.shape[1] # Número de dimensiones\n",
    "    cdef unsigned short M = Z.shape[0] # Número de muestras a entrenar\n",
    "        \n",
    "    # Exponente inv\n",
    "    cdef double expo = 1.0/p;\n",
    "    \n",
    "    # Indices de los k mas cercanos\n",
    "    cdef unsigned short [:] kInds = np.zeros(k,dtype='uint16')\n",
    "    \n",
    "    # Distancias de los k mas cercanos\n",
    "    cdef double [:] kDists = np.zeros(k,dtype='float64')\n",
    "    \n",
    "    # Indice de la distancia más grande ( dentro de las k más pequeñas )\n",
    "    cdef unsigned short maxDistIndex = 0\n",
    "    \n",
    "    # Indice de la clase ganadora\n",
    "    cdef unsigned short winnerClassIndex = 0\n",
    "    cdef double winnerClassDist = 0.0\n",
    "    \n",
    "    # Variable para almacenar suma de distancias inversas por clase ( para decidir clase )\n",
    "    cdef double [:] cRes = np.zeros(C,dtype='float64')\n",
    "    \n",
    "    # Variable temporal para calcular distancia\n",
    "    cdef double dist = 0.0\n",
    "    \n",
    "    # Resultados\n",
    "    cdef unsigned char [:] YZ = np.zeros(M,dtype='uint8')\n",
    "    \n",
    "    # Loop cada elemento de Z\n",
    "    for i in range(M):\n",
    "        \n",
    "        # Reinicia el índice de la clase ganadora\n",
    "        winnerClassIndex = 0\n",
    "        winnerClassDist = 0.0\n",
    "        \n",
    "        # Reinicia la suma de distancias inversas por clase\n",
    "        for d in range(C):\n",
    "            cRes[d] = 0.0\n",
    "            \n",
    "        # Asigna un valor inicial grande a las distancias\n",
    "        for d in range(k):\n",
    "            kDists[d] = 1.7976931348623157e+308 # Máximo valor de un double\n",
    "        \n",
    "        # Asigna la primera distancia como la mayor ( inicialmente son todas iguales)\n",
    "        maxDistIndex = 0\n",
    "        \n",
    "        # Loop cada elemento de X\n",
    "        for j in range(N):\n",
    "            \n",
    "            # Calcula distancia\n",
    "            dist = 0.0\n",
    "            for d in range(D):\n",
    "                dist += pow(fabs(Z[i,d] - X[j,d]),p)\n",
    "            dist = pow(dist,expo)\n",
    "            \n",
    "            # Si la distancia es menor que la mayor en kDists\n",
    "            if dist < kDists[maxDistIndex]:\n",
    "                \n",
    "                # Reemplaza el valor\n",
    "                kDists[maxDistIndex] = dist\n",
    "                \n",
    "                # Guarda el índice del elemento X actual\n",
    "                kInds[maxDistIndex] = j\n",
    "                \n",
    "                # Vuelve a buscar el mayor actual en kDists\n",
    "                dist = 0\n",
    "                for l in range(k):\n",
    "                    if kDists[l] > dist:\n",
    "                        dist = kDists[l]\n",
    "                        maxDistIndex = l\n",
    "        \n",
    "        # Calcula la cercanía ponderada por distancia de cada clase\n",
    "        for d in range(k):\n",
    "            \n",
    "            # Suponiendo que los nombres de las clases siempre son 0,1,...,C-1\n",
    "            cRes[Y[kInds[d]]] += 1.0/kDists[d]\n",
    "            \n",
    "        # Busca la clase ganadora\n",
    "        for d in range(C):\n",
    "            if cRes[d] > winnerClassDist:\n",
    "                winnerClassDist = cRes[d]\n",
    "                winnerClassIndex = d\n",
    "        \n",
    "        # Guarda la clase ganadora en el arreglo\n",
    "        YZ[i] = c[winnerClassIndex]\n",
    "                        \n",
    "            \n",
    "    return YZ.base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto logramos reducir el tiempo de 470 ms a 19 ms, 100 veces más rápida que la inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKNN3\n",
    "Por último, utilizamos multithreading con OpenMP, por lo que simplemente portamos el código anterior para poder paralelizar el **for** que calcula los K vecinos de cada elemento de Z. \n",
    "En nuestra máquina obtuvimos mejores resutlados con 12 hilos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%cython -l m --compile-args=-fopenmp --link-args=-fopenmp --force\n",
    "\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as npc\n",
    "from cython.parallel import prange\n",
    "\n",
    "cdef extern from \"math.h\" nogil:\n",
    "    double fabs(double)\n",
    "    double pow(double,double)\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.initializedcheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cpdef npc.ndarray CKNN3(double [:,::1] X, long [:] Y, double [:,::1] Z, unsigned char k=5, double p = 2.0):\n",
    "    \n",
    "    # Clases\n",
    "    cdef long [:] c = np.unique(Y) \n",
    "    \n",
    "    cdef unsigned short C = c.shape[0] # Número de clases\n",
    "    cdef unsigned short N = X.shape[0] # Número de muestras conocidas\n",
    "    cdef unsigned short D = X.shape[1] # Número de dimensiones\n",
    "    cdef unsigned short M = Z.shape[0] # Número de muestras a entrenar\n",
    "        \n",
    "    # Exponente inv\n",
    "    cdef double expo = 1.0/p;\n",
    "    \n",
    "    # Indices de los k mas cercanos\n",
    "    cdef unsigned short [:,::1] kInds = np.zeros((M,k),dtype='uint16')\n",
    "    \n",
    "    # Distancias de los k mas cercanos\n",
    "    cdef double [:,::1] kDists = np.full((M,k),1.7976931348623157e+308,dtype='float64')\n",
    "    \n",
    "    # Indice de la distancia más grande ( dentro de las k más pequeñas )\n",
    "    cdef unsigned short [:] maxDistIndex = np.zeros(M,dtype='uint16')\n",
    "    \n",
    "    # Indice de la clase ganadora\n",
    "    cdef unsigned short [:] winnerClassIndex = np.zeros(M,dtype='uint16')\n",
    "    cdef double [:] winnerClassDist = np.zeros(M,dtype='float64')\n",
    "    \n",
    "    # Variable para almacenar suma de distancias inversas por clase ( para decidir clase )\n",
    "    cdef double [:,::1] cRes = np.zeros((M,C),dtype='float64')\n",
    "    \n",
    "    # Variable temporal para calcular distancia\n",
    "    cdef double [:] dist = np.zeros(M,dtype='float64')\n",
    "    \n",
    "    # Resultados\n",
    "    cdef unsigned char [:] YZ = np.zeros(M,dtype='uint8')\n",
    "    \n",
    "    # Indices\n",
    "    cdef short i,j,d,l = 0\n",
    "    \n",
    "    # Loop cada elemento de Z\n",
    "    with nogil:\n",
    "        for i in prange(M,num_threads=12):\n",
    "\n",
    "            # Loop cada elemento de X\n",
    "            for j in range(N):\n",
    "\n",
    "                # Calcula distancia\n",
    "                dist[i] = 0.0\n",
    "                for d in range(D):\n",
    "                    dist[i] += pow(fabs(Z[i,d] - X[j,d]),p)\n",
    "                dist[i] = pow(dist[i],expo)\n",
    "\n",
    "                # Si la distancia es menor que la mayor en kDists\n",
    "                if dist[i] < kDists[i,maxDistIndex[i]]:\n",
    "\n",
    "                    # Reemplaza el valor\n",
    "                    kDists[i,maxDistIndex[i]] = dist[i]\n",
    "\n",
    "                    # Guarda el índice del elemento X actual\n",
    "                    kInds[i,maxDistIndex[i]] = j\n",
    "\n",
    "                    # Vuelve a buscar el mayor actual en kDists\n",
    "                    dist[i] = 0\n",
    "                    for l in range(k):\n",
    "                        if kDists[i,l] > dist[i]:\n",
    "                            dist[i] = kDists[i,l]\n",
    "                            maxDistIndex[i] = l\n",
    "\n",
    "            # Calcula la cercanía ponderada por distancia de cada clase\n",
    "            for d in range(k):\n",
    "\n",
    "                # Suponiendo que los nombres de las clases siempre son 0,1,...,C-1\n",
    "                cRes[i,Y[kInds[i,d]]] += 1.0/kDists[i,d]\n",
    "\n",
    "            # Busca la clase ganadora\n",
    "            for d in range(C):\n",
    "                if cRes[i,d] > winnerClassDist[i]:\n",
    "                    winnerClassDist[i] = cRes[i,d]\n",
    "                    winnerClassIndex[i] = d\n",
    "\n",
    "            # Guarda la clase ganadora en el arreglo\n",
    "            YZ[i] = c[winnerClassIndex[i]]\n",
    "                        \n",
    "            \n",
    "    return YZ.base\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta última mejora, logramos reduir el tiempo de 19 ms a 4.8 ms, 400 veces más rápida que la inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN de Sklearn\n",
    "\n",
    "También implementamos la versión de KNN para comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnKNN(x,y,z):\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5,weights='distance',p=2)\n",
    "    knn.fit(x,y)\n",
    "    return knn.predict(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "### KKN original con Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r4 -n4 KNN(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora 1 KKN con Cython ( distancia )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r4 -n4 CKNN1(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora 2 KKN con Cython ( sorting )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r4 -n4 CKNN2(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora 3 KKN con Cython ( multithreading )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r4 -n4 CKNN3(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de KKN de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r4 -n4 sklearnKNN(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver nuestra mejor versión tarda aproximadamente 4.8 ms, lo cual es una gran mejora respecto a la función inicial, pero la versión de sklearn sigue siendo el doble de rápida, aún no utilizando multithreading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificamos si se obtienen los mismos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultado con KNN Python\n",
    "ZY = KNN(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNN == CKNN1:\\t\\t\",(ZY == CKNN1(x,y,z)).all())\n",
    "print(\"KNN == CKNN2:\\t\\t\",(ZY == CKNN2(x,y,z)).all())\n",
    "print(\"KNN == CKNN3:\\t\\t\",(ZY == CKNN3(x,y,z)).all())\n",
    "print(\"KNN == sklearnKNN:\\t\",(ZY == sklearnKNN(x,y,z)).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las funciones entregan numéricamente el mismo resultado. Sin embargo el tipo de dato de los arreglos numpy que retorna nuestro KNN es **uint8**, a diferencia de la función original que es **float64**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Gráfica del Speed-up\n",
    "\n",
    "Calculamos el speed-up dividiendo los tiempos del KNN original por los de nuestro mejor KNN ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaños de muestras\n",
    "N = np.array([10,50,100,500,1000,5000,10000])\n",
    "\n",
    "def calcula_tiempos():\n",
    "    # Almacena tiempos\n",
    "    times = np.zeros((len(N),2),dtype='float64')\n",
    "\n",
    "    # Calculamos valores\n",
    "    for i in range(len(N)):\n",
    "        e, t = create_data(N=N[i])\n",
    "        xx, yy = e\n",
    "        zz, _ = t\n",
    "        timeit1 = %timeit -r1 -n1 -o CKNN3(xx,yy,zz)\n",
    "        timeit2 = %timeit -r1 -n1 -o KNN(xx,yy,zz)\n",
    "        times[i,0] = timeit1.best\n",
    "        times[i,1] = timeit2.best\n",
    "        \n",
    "    # Almacenamos resultados\n",
    "    np.save(\"Tiempos.npy\",times)\n",
    "\n",
    "# Desactivamos ya que requiere mucho tiempo\n",
    "#calcula_tiempos()\n",
    "\n",
    "# Cargamos resultados calculados previamente\n",
    "times = np.load(\"Tiempos.npy\")\n",
    "\n",
    "# Calculamos speedups\n",
    "speedups = times[:,1]/times[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,6),tight_layout=True)\n",
    "ax.set_title('Curva de Speedup')\n",
    "ax.set_ylabel('T KNN / T CKNN')\n",
    "plt.plot(N, speedups, c='red',alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la curva se observa que a partir de las 5000 muestras, donde nuestro KNN resulta ser aproximadamente 600 veces más rápido que el KNN original, el aumento de speedup se estabiliza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validación cruzada\n",
    "\n",
    "Antes de comenzar a entrenar nuestro modelo, verificamos el balance de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(9,6),tight_layout=True)\n",
    "_ = plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = np.arange(1,31,dtype='float64')\n",
    "p_values = np.arange(1,11,dtype='float64')\n",
    "\n",
    "# Almacena todos los resultados (Acurracy_avg,k,p)\n",
    "all_params = np.zeros((len(k_values)*len(p_values),3))\n",
    "\n",
    "# Mejor resultado (Acurracy_avg,k,p)\n",
    "best_params = np.zeros(3,dtype='float64')\n",
    "\n",
    "# kFold de 7 divisiones\n",
    "kf = KFold(n_splits=7,shuffle=True,random_state=0)\n",
    "\n",
    "# Validación cruzada para encontrar mejor k y p\n",
    "index = 0\n",
    "for k in k_values:\n",
    "    for p in p_values:\n",
    "        avg_acurracy = 0.0\n",
    "        for train_index, val_index in kf.split(x):\n",
    "\n",
    "            # Realiza predicción\n",
    "            zy = CKNN3(x[train_index],y[train_index],x[val_index],k,p)\n",
    "\n",
    "            # Valores correctos / total\n",
    "            avg_acurracy += float(np.count_nonzero((zy == y[val_index])))/float(len(zy))\n",
    "\n",
    "        # Almacena Acurracy, k y p\n",
    "        all_params[index,0] = avg_acurracy/float(kf.n_splits)\n",
    "        all_params[index,1] = k\n",
    "        all_params[index,2] = p\n",
    "\n",
    "        # Guarda mejor Acurracy y parámetros\n",
    "        if all_params[index,0] > best_params[0]:\n",
    "            best_params = all_params[index,:]\n",
    "        index+=1\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, con un accuracy de 0.9515873, se obtuvo el valor de k = 17 y p = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Métricas que evalúan el clasificador\n",
    "Se implementaron distintas métricas que permiten evaluar la exactitud y desempeño de los algoritmos KNN al momento de identificar las dos mitades de círculos entrelazados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Matriz de Confusión\n",
    "La matriz de confusión es una herramienta muy útil para valorar cómo de bueno es un modelo clasificación basado en aprendizaje automático. En particular, sirve para mostrar de forma explícita cuándo una clase es confundida con otra, lo cual nos, permite trabajar de forma separada con distintos tipos de error. \n",
    "\n",
    "En una matriz de confusión, por lo general:\n",
    "\n",
    "- los elementos de la diagonal representan las clasificaciones correctas\n",
    "\n",
    "- los elementos fuera de la diagonal representan las clasificaciones erroneas\n",
    "\n",
    "- las filas corresponden a las clases reales\n",
    "\n",
    "- las columnas corresponden a las clases predichas por el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4), tight_layout=True)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 17, weights='distance', p=2)\n",
    "knn.fit(z,w) # conjunto T\n",
    "\n",
    "plot_confusion_matrix(knn, # Clasificador\n",
    "                      z, # Datos\n",
    "                      w, # Etiquetas\n",
    "                      ax=ax, # subeje para gráficar\n",
    "                      display_labels=np.array(['Naranjo', 'Azul']), #Nombres de las clases\n",
    "                      cmap=plt.cm.plasma, # Escala de colores\n",
    "                      normalize=None #Permite escoger entre cantidades y porcentajes\n",
    "                     );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz muestra que no hubo ningún error al clasificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Exactitud\n",
    "El accuracy se calcula como la cantidad de ejemplos predichos correctamente dividido por la cantidad total de ejemplos y es un valor en el rango [0,1]. Por definición corresponde a la suma de la diagonal de la matriz de confusión dividido por el total de ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "what = knn.predict(z)\n",
    "\n",
    "print(\"accuracy:\", (accuracy_score(w, what)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo el valor esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Curva de desempeño\n",
    "\n",
    "En problemas de clasificación binaria es mucho más informativo medir el desempeño utilizando curvas Receiver operating characteristic (ROC), que son curvas en las que se presenta la sensibilidad (o verdaderos positivos) en función de los falsos positivos (complementario de la especificidad) para distintos puntos de corte.\n",
    "\n",
    "A modo de resumen, una interpretación superficial de las curvas sigue la siguiente figura.\n",
    "\n",
    "<img src=\"images/roc.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(w, knn.predict_proba(z)[:, 1])\n",
    "idx = np.where(tpr > 0.9)[0][0]\n",
    "print(f\"{fpr[idx]:0.4f}, {tpr[idx]:0.4f}, {thresholds[idx]:0.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(fpr, tpr)\n",
    "ax.scatter(fpr[idx], tpr[idx], s=50, c='k')\n",
    "ax.set_xlabel('Tasa de falsos positivos')\n",
    "ax.set_ylabel('Tasa de verdaderos positivos');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo la mejor curva posible, lo cual es consistente con lo que vimos en la matriz de confusión y el *accuracy*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
